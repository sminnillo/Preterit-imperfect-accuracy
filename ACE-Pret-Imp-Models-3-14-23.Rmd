---
title: "Preterit-Imperfect Appropriate Use Models 3-14-23"
author: "Sophia Minnillo"
date: "3/14/2023"
output:
  pdf_document:
    toc: yes
    toc_depth: '2'
  html_document:
    toc: yes
    toc_depth: 2
    theme: cerulean
    highlight: tango
---

This is based on summing before log-transforming data.

## Set-up

```{r setup, include=FALSE}
#packages
library(MASS)
library(MuMIn)
library(tidyverse)
library(stringr)
library(broom)
library(lme4)
library(psych)
library(afex)
library(effects) 
#library(sjstats)#also for visuals
library(ngramr)
library(Rmisc) #for SummarySE
library(farver)
library(interactions)
library(effsize)
library(emmeans)
#install.packages('magrittr')
library(magrittr)
#install.packages('ggeffects')
library(ggeffects)
#install.packages('sjmisc')
library(sjmisc)
```

```{r setup1, include=FALSE}
#load one relevant CSV
data <- read_csv('cows_pret_imp_master_for_models_no_se_cde_011623.csv')%>%
  dplyr::filter(Ambiguous != 1) #added 10-26-22
#1917 observations, preterit & imperfect
#this data is filtered for outliers in frequency
#updated 9-28-22 with cleaned infinitives (no reflexive particles)
#view(data)

#cedel2 with participants who participated in both modalities data
csv_cedel2_duplicates_only <- read_csv('csv_cedel2_duplicates_only_cde_011623.csv')%>%
  dplyr::filter(Ambiguous != 1) #added 10-26-22
#view(csv_cedel2_duplicates_only)
#360 observations
```

# COWS cross-sectional data

## 1: does accuracy of use differ between SPA 1 and all other course levels?

This is using the data from COWS: cross-sectional

```{r avisual}
#just cows data can use
data_cows <- data %>%
  dplyr::filter(Subset == 'COWS_cross')
#view(data_cows)

#course levels
course_levelsb = c('SPA 1', 'SPA 2', 'SPA 3', 'SPA 21', 'SPA 22', 'SPA 23', 'SPA 24')

#for this RQ
data_rq1 <- data_cows %>%
  group_by(Corrected_num, Proficiency) %>%
  dplyr::summarize(`Mean Appropriateness` = mean(appropriateness))%>%
  dplyr::mutate(Proficiency = factor(Proficiency, levels = course_levelsb))
#view(data_rq1)

#plot
ggplot(data_rq1,
       aes(x = Proficiency, y = `Mean Appropriateness`))+
  geom_col()+
  facet_wrap(~Corrected_num)+
  theme(axis.text.x = element_text(angle = 45, hjust = 0.75, vjust = 0.9))+
  ylim(0,1)
```

Chi-squared test of differences between pre and direct post instruction groups.

```{r b}
#separate into pre vs. post instruction
data_rq1_pre_instruction <- data_cows %>%
  filter(Proficiency == 'SPA 1')
#view(data_rq1_pre_instruction)

data_rq1_post_instruction <- data_cows %>%
  filter(Proficiency != 'SPA 1')
#view(data_rq1_post_instruction)

#only SPA 2
data_rq1_post_instruction_SPA2 <- data_cows %>%
  filter(Proficiency == 'SPA 2')

#view(data_rq1_post_instruction_SPA2)
#filtering down data to just SPA 1 and 2
data_cows_SPA1and2 <- data_cows %>%
  dplyr::filter(Proficiency == 'SPA 1' | Proficiency == 'SPA 2')%>%
  dplyr::select(c(Proficiency, appropriateness))%>%
  mutate(appropriateness = as.character(appropriateness))
#view(data_cows_SPA1and2)

#now get counts by category
# data_cows_SPA1and2_sum <- data_cows_SPA1and2 %>%
#   group_by(Proficiency, appropriateness)%>%
#   dplyr::summarize(count = n())%>%
#   pivot_wider(names_from = 'appropriateness', values_from = 'count')

#view(data_cows_SPA1and2_sum)

#ok actually this is what we need to use
table(data_cows_SPA1and2$Proficiency, data_cows_SPA1and2$appropriateness)

chisq.test(table(data_cows_SPA1and2$Proficiency, data_cows_SPA1and2$appropriateness))
```

There is a significant difference between pre-instructed and instructed learners.

## 2: Is course level a predictor of accuracy? No.

```{r c}
#now just use SPA 2 on: data_rq1_post_instruction

#now, we'll be considering tense (binary), regularity (binary), and frequency (log-transformed continuous)
#tense and regularity will become +/- 0.5

#now let's center and scale the frequency data
center_scale <- function(x) {
    scale(x, scale = TRUE) #changed 9-28-22
  #scale = TRUE to center and scale
}
#this is from this blog https://www.gastonsanchez.com/visually-enforced/how-to/2014/01/15/Center-data-in-R/

#need to center the course levels
#SPA 2 = -2.5
#SPA 3 = -1.5
#SPA 21 = -.5
#SPA 22 = .5
#SPA 23 = 1.5
#SPA 24 = 2.5

#turn Proficiency levels into centered variable
data_rq1_post_instruction <- data_rq1_post_instruction %>%
  mutate(course_level = case_when(
    Proficiency == 'SPA 2' ~ 'level 2',
    Proficiency == 'SPA 3' ~ 'level 3',
    Proficiency == 'SPA 21' ~ 'level 4',
    Proficiency == 'SPA 22' ~ 'level 5',
    Proficiency == 'SPA 23' ~ 'level 6',
    Proficiency == 'SPA 24' ~ 'level 7'
  ))%>%
  mutate(course_level_cont = case_when(
    Proficiency == 'SPA 2' ~ -2.5,
    Proficiency == 'SPA 3' ~ -1.5,
    Proficiency == 'SPA 21' ~ -0.5,
    Proficiency == 'SPA 22' ~ 0.5,
    Proficiency == 'SPA 23' ~ 1.5,
    Proficiency == 'SPA 24' ~ 2.5
  ))%>%
  mutate(tense = case_when(
    Corrected_num == 'imperfect' ~ -0.5, #imperfect negative
    Corrected_num == 'preterit' ~ 0.5 #preterit positive
  ))%>%
  mutate(regularity = case_when(
    Regularity == 'I' ~ -0.5, #irregular is -0.5
    Regularity == 'R' ~ 0.5 #regular is 0.5 (positive)
  ))%>%
  mutate(
    #change 11-11-22: frequency as sum_log_frq
    frequency = center_scale(data_rq1_post_instruction$log_sum_frq)
    #frequency now ranges from approx. -2.7 to +1.53
  )%>%
  drop_na(regularity)%>% #getting rid of NAs, still 1801 observations
  mutate(
    infinitive = tolower(Infinitive_no_reflex)
  ) #change 9-28
#view(data_rq1_post_instruction)
```

## Preterit

```{r d1}
#just the preterit
data_rq1_post_instruction_pret <- data_rq1_post_instruction%>%
  filter(Corrected_num == 'preterit')
#view(data_rq1_post_instruction_pret)

modelrq3_1_1 <- glmer(appropriateness ~ course_level+
                      (1|Essay) + (1|infinitive), data_rq1_post_instruction_pret,
                  family = 'binomial', control = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=50000)))
summary(modelrq3_1_1)
#eliminated contrasts = list(course_level=contr.sdif), 9-28-22
```

Now, we're going to run a model for the imperfect without course level to see if it's an important predictor

```{r letssee12}
#view(data_rq1_post_instruction_pret)
modelrq3_1_2_sm <- glmer(appropriateness ~ 1 + #no fixed effects
                      (1|Essay) + (1|infinitive), data_rq1_post_instruction_pret,
                  family = 'binomial', control = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=50000)))
summary(modelrq3_1_2_sm)
```

Model comparison: is course level useful to predicting preterit accuracy?

Resource for how doing: <https://www.ssc.wisc.edu/sscc/pubs/MM/MM_TestEffects.html>

```{r letsseeabcde}
#view(data_rq1_post_instruction_pret)
aov1 <- anova(modelrq3_1_1,modelrq3_1_2_sm,test="Chisq")
aov1
```

No difference made by adding course level. Model without is 'better' model.

## Imperfect

```{r d2}
#just the imperfect
data_rq1_post_instruction_imp <- data_rq1_post_instruction%>%
  filter(Corrected_num == 'imperfect')
#view(data_rq1_post_instruction_imp)
modelrq3_1_2 <- glmer(appropriateness ~ course_level+
                      (1|Essay) + (1|infinitive), data_rq1_post_instruction_imp,
                  family = 'binomial', control = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=50000)))
summary(modelrq3_1_2)
#eliminated contrasts = list(course_level=contr.sdif), 9-28-22
```

Now, we're going to run a model for the imperfect without course level to see if it's an important predictor

```{r letssee}
#view(data_rq1_post_instruction_imp)
modelrq3_1_3 <- glmer(appropriateness ~ 1 + #no fixed effects
                      (1|Essay) + (1|infinitive), data_rq1_post_instruction_imp,
                  family = 'binomial', control = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=50000)))
summary(modelrq3_1_3)
```

Model comparison: is course level useful to predicting imperfect accuracy?

```{r letssee1}
#view(data_rq1_post_instruction_imp)
aov1 <- anova(modelrq3_1_2,modelrq3_1_3,test="Chisq")
aov1
```

There is no significant effect of including course level in the model. In fact, the AIC value is lower when course level is ommitted.

```{r d-imperfect-differences}
#resource: https://aosmith.rbind.io/2019/03/25/getting-started-with-emmeans/
#get differences between levels
a <- emmeans(modelrq3_1_2, specs = 'course_level', type = "response")
a
b <- contrast(a)
b
```

fdr = false discovery rate

Why is df = inf? Actually it's totally fine: <https://cran.r-project.org/web/packages/emmeans/vignettes/FAQs.html#asymp>

SPA 21 and 23 are less appropriate (on verge of our 95% confidence level) for use of the imperfect. Interesting because this is when they're reviewed again in the composition series..?

This might be a question of overall suppliance. Students are overall marking the imperfect a lot less in SPA 21 as compared to other levels (see suppliance visualizations). 70% were personal stories, so the task doesn't explain it. Maybe it's been 2 quarters since students learned it and they're just not focused on the imperfect anymore?

## Both

```{r c123}
#now let's model appropriateness without SPA 1
modelrq3_1 <- glmer(appropriateness ~ course_level +
                      (1|Essay) + (1|infinitive), data_rq1_post_instruction,
                  family = 'binomial', control = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=50000)))

#appropriate (0=no, 1=yes) ~ 
#* Proficiency + random effect for essay and infinitive
summary(modelrq3_1)

#, contrasts = list(course_level=contr.sdif)
#eliminated 9-28-22 to consider course level as a *categorical* variable
```

According to this analysis (which is of both tense-aspect forms), course level 6 (SPA 23) is ALMOST but not quite significantly different from the others in accuracy.

Course level \* Tense

```{r c123today}
#now let's model appropriateness without SPA 1
modelrq3_1_sm <- glmer(appropriateness ~ course_level * tense +
                      (1+tense||Essay) + (1|infinitive), data_rq1_post_instruction,
                  family = 'binomial', control = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=50000)))

#appropriate (0=no, 1=yes) ~ 
#* 1 + random effect for essay and infinitive
summary(modelrq3_1_sm)
```

Course level + tense-aspect

```{r c123todaytomorrow}
#now let's model appropriateness without SPA 1
modelrq3_1_sm1000 <- glmer(appropriateness ~ course_level + tense +
                      (1+tense||Essay) + (1|infinitive), data_rq1_post_instruction,
                  family = 'binomial', control = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=50000)))

#appropriate (0=no, 1=yes) ~ 
#* 1 + random effect for essay and infinitive
summary(modelrq3_1_sm1000)
```

Just Tense

```{r c123today1}
#now let's model appropriateness without SPA 1
modelrq3_1_sm1 <- glmer(appropriateness ~ tense +
                      (1+tense||Essay) + (1|infinitive), data_rq1_post_instruction,
                  family = 'binomial', control = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=50000)))

#appropriate (0=no, 1=yes) ~ 
#* 1 + random effect for essay and infinitive
summary(modelrq3_1_sm1)
```

Model comparison: is course level useful to predicting both tenses' accuracy?

```{r letssee3}
#view(data_rq1_post_instruction)
aov2 <- anova(modelrq3_1_sm,modelrq3_1_sm1,modelrq3_1_sm1000,test="Chisq")
aov2
```

No real difference between the models, AIC is lower without course level --\> course level not needed in models to explain variance.


# 3: Accuracy- COWS together

Backwards model selection

## Model 2 : apr \~ frq \* reg \* tense + (1+frq \* reg \* tense \|\|essay) + (1\|inf)

```{r new11122214}
#data_rq1_post_instruction
model21 <- glmer(appropriateness ~ tense + frequency + regularity +
                  tense:frequency + frequency:regularity + tense:regularity + tense:frequency:regularity +
                  (1+ frequency*tense*regularity||Essay) + (1|infinitive), data_rq1_post_instruction,
                  family = 'binomial', control = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=50000)))
summary(model21)
```

Taking away 3-way interaction

## Model 2.1 : apr \~ frq + reg + tense + 2-way interactions + (1+frq + reg + tense + 2-way interactions \|\|essay) + (1\|inf)

```{r new11122214zyq}
#data_rq1_post_instruction
model21 <- glmer(appropriateness ~ tense + frequency + regularity +
                  tense:frequency + frequency:regularity + tense:regularity +
                  (1+ tense + frequency + regularity +
                  tense:frequency + frequency:regularity + tense:regularity||Essay) + (1|infinitive), data_rq1_post_instruction,
                  family = 'binomial', control = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=50000)))
summary(model21)
```

Significant effects of tense and frequency

## Model 2.2 : apr \~ frq + reg + tense + 2-way interactions without frequency:regularity + (1+frq + reg + tense + 2-way interactions without frequency:regularity \|\|essay) + (1\|inf)

```{r new11122214abcabcabcabc}
#data_rq1_post_instruction
model21 <- glmer(appropriateness ~ tense + frequency + regularity +
                  tense:frequency + tense:regularity +
                  (1+ tense + frequency + regularity +
                  tense:frequency + tense:regularity||Essay) + (1|infinitive), data_rq1_post_instruction,
                  family = 'binomial', control = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=50000)))
summary(model21)
```


## Model 2.3 : apr \~ frq + reg + tense + 2-way interactions without frequency:regularity or tense:regularity + (1+frq + reg + tense + 2-way interactions without frequency:regularity or tense:regularity \|\|essay) + (1\|inf)

```{r new11122214abcabcabc}
#data_rq1_post_instruction
model21 <- glmer(appropriateness ~ tense + frequency + regularity +
                  tense:frequency +
                  (1+ tense + frequency + regularity +
                  tense:frequency||Essay) + (1|infinitive), data_rq1_post_instruction,
                  family = 'binomial', control = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=50000)))
summary(model21)
```

#in paper currently

## *Model 2.4 : apr \~ frq + reg + tense + without 2-way interactions + (1+frq + reg + tense + without 2-way interactions \|\|essay) + (1\|inf)

```{r new11122214abcabc}
#data_rq1_post_instruction
model21 <- glmer(appropriateness ~ tense + frequency + regularity +
                  (1+ tense + frequency + regularity||Essay) + (1|infinitive), data_rq1_post_instruction,
                  family = 'binomial', control = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=50000)))
summary(model21)
```

#Cohen's d

```{r emmeans1}
#get cohen's d
#divide into groups by tense
#calculate Cohen's d
cohen.d(data_rq1_post_instruction_pret$appropriateness, data_rq1_post_instruction_imp$appropriateness)
#medium according to P&O 2014

#effect size by regularity?
reg <- data_rq1_post_instruction %>%
  filter(Regularity == 'R')

irreg <- data_rq1_post_instruction %>%
  filter(Regularity == 'I')
#view(data_rq1_post_instruction)

cohen.d(reg$appropriateness, irreg$appropriateness)
#negligeable effect size
```
# 3: Preterit

## \*Model 1.3 : apr \~ frq + (1+ frequency\|\|essay) + (1\|inf)

```{r new300}
#data_rq1_post_instruction_pret
model3 <- glmer(appropriateness ~ frequency + 
                  (1+ frequency||Essay) + (1|infinitive), data_rq1_post_instruction_pret,
                  family = 'binomial', control = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=50000)))
summary(model3)
```

Still no sig effect.


# 3: Imperfect

## \*Model 1.3 : apr \~ frq + (1+ frequency\|\|essay) + (1\|inf)

```{r new303}
#now using data_rq1_post_instruction_imp_reg
model3 <- glmer(appropriateness ~ frequency + 
                  (1+ frequency||Essay) + (1|infinitive), data_rq1_post_instruction_imp,
                  family = 'binomial', control = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=50000)))
summary(model3)
```

Significant, positive effect of frequency.

# 4: CEDEL2 cross-sectional data

I'm using the repeated subjects data set.

##set-up

```{r kqq}
#set-up
#going to do the same data cleaning/preparation tasks as I did before

csv_cedel2_duplicates_only <- csv_cedel2_duplicates_only %>%
  mutate(modality = case_when(
    Modality == 'Spoken' ~ -0.5, #imperfect negative
    Modality == 'Written' ~ 0.5 #preterit positive
  ))%>%
  mutate(tense = case_when(
    Corrected_num == 'imperfect' ~ -0.5, #imperfect negative
    Corrected_num == 'preterit' ~ 0.5 #preterit positive
  ))%>%
  mutate(regularity = case_when(
    Regularity == 'I' ~ -0.5, #irregular is -0.5
    Regularity == 'R' ~ 0.5 #regular is 0.5 (positive)
  ))%>%
  mutate(
    #changed 1-16-23 to reflect new data
    frequency = center_scale(csv_cedel2_duplicates_only$log_sum_frq)
  )%>%
  drop_na(regularity)%>% #getting rid of NAs; becomes 356 data points
  mutate(
    infinitive = tolower(Infinitive_no_reflex)
  )
view(csv_cedel2_duplicates_only)

#separate by tense
csv_cedel2_duplicates_only_pret <- csv_cedel2_duplicates_only%>%
  filter(Corrected_num == 'preterit')

csv_cedel2_duplicates_only_imp <- csv_cedel2_duplicates_only%>%
  filter(Corrected_num == 'imperfect')
```

## show differences in accuracy based on tense

```{r mnm}
#get error bars
t_summary1 <- summarySE(csv_cedel2_duplicates_only,
                        measurevar="appropriateness",
                        groupvars=c("Corrected_num"))
#view(t_summary1)

# Use 95% confidence intervals instead of SEM
ggplot(t_summary1, aes(x=Corrected_num, y=appropriateness)) + 
    geom_bar(position=position_dodge(), stat="identity") +
    geom_errorbar(aes(ymin=appropriateness-ci, ymax=appropriateness+ci),
                  width=.2,                    # Width of the error bars
                  position=position_dodge(.9))+
  ylim(0,1)

#no irregular verbs dataset
csv_cedel2_duplicates_only_reg <- csv_cedel2_duplicates_only %>%
  filter(regularity == 0.5)

#view(csv_cedel2_duplicates_only_reg)
#removes about 90 data points
```

# Both tenses together

## Model 0 : apr \~ tense \* freq \* regularity \* modality + (1+tense \* freq \* regularity \* modality\|\|Name) + (1\|inf)

```{r anotheroneabcagain1}
model1 <- glmer(appropriateness ~ tense * modality * frequency * regularity +
                  (1+tense * modality * frequency * regularity||Name) + (1|infinitive), csv_cedel2_duplicates_only,
                  family = 'binomial', control = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=50000)))

summary(model1)
```

## Model 0.1 : no 4-way interaction

```{r anotheroneabcagain2}
model1 <- glmer(appropriateness ~ tense + modality + frequency + regularity + tense:modality + tense:frequency + tense:regularity + modality:frequency + modality:regularity + frequency:regularity + tense:modality:frequency + tense:modality:regularity + tense:frequency:regularity + modality:frequency:regularity +
                  (1+tense + modality + frequency + regularity + tense:modality + tense:frequency + tense:regularity + modality:frequency + modality:regularity + frequency:regularity + tense:modality:frequency + tense:modality:regularity + tense:frequency:regularity + modality:frequency:regularity||Name) + (1|infinitive), csv_cedel2_duplicates_only,
                  family = 'binomial', control = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=50000)))

summary(model1)
```

## Model 0.2 : no 3-way interactions

```{r anotheroneabcagain12}
model1 <- glmer(appropriateness ~ tense + modality + frequency + regularity + tense:modality + tense:frequency + tense:regularity + modality:frequency + modality:regularity + frequency:regularity  +
                  (1+tense + modality + frequency + regularity + tense:modality + tense:frequency + tense:regularity + modality:frequency + modality:regularity + frequency:regularity||Name) + (1|infinitive), csv_cedel2_duplicates_only,
                  family = 'binomial', control = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=50000)))

summary(model1)
```

## Model 0.3 : no 3-way interactions, clearing out 2-way interactions

```{r anotheroneabcagain123}
model1 <- glmer(appropriateness ~ tense + modality + frequency + regularity + tense:modality + tense:regularity + modality:frequency + modality:regularity + frequency:regularity  +
                  (1+tense + modality + frequency + regularity + tense:modality + tense:regularity + modality:frequency + modality:regularity + frequency:regularity||Name) + (1|infinitive), csv_cedel2_duplicates_only,
                  family = 'binomial', control = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=50000)))

summary(model1)
```

## Model 0.4 : no 3-way interactions, clearing out 2-way interactions (tense:modality)

```{r anotheroneabcagain1234}
model1 <- glmer(appropriateness ~ tense + modality + frequency + regularity + tense:regularity + modality:frequency + modality:regularity + frequency:regularity  +
                  (1+tense + modality + frequency + regularity  + tense:regularity + modality:frequency + modality:regularity + frequency:regularity||Name) + (1|infinitive), csv_cedel2_duplicates_only,
                  family = 'binomial', control = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=50000)))

summary(model1)
```

## Model 0.5 : no 3-way interactions, clearing out 2-way interactions (tense:regularity)

```{r anotheroneabcagain12345}
model1 <- glmer(appropriateness ~ tense + modality + frequency + regularity + modality:frequency + modality:regularity + frequency:regularity  +
                  (1+tense + modality + frequency + regularity + modality:frequency + modality:regularity + frequency:regularity||Name) + (1|infinitive), csv_cedel2_duplicates_only,
                  family = 'binomial', control = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=50000)))

summary(model1)
```

## Model 0.6 : no 3-way interactions, clearing out 2-way interactions (modality:frequency)

```{r anotheroneabcagain123456}
model1 <- glmer(appropriateness ~ tense + modality + frequency + regularity + modality:regularity + frequency:regularity  +
                  (1+tense + modality + frequency + regularity + modality:regularity + frequency:regularity||Name) + (1|infinitive), csv_cedel2_duplicates_only,
                  family = 'binomial', control = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=50000)))

summary(model1)
```

## Model 0.7 : no 3-way interactions, clearing out 2-way interactions (frequency:regularity)

```{r anotheroneabcagain1234567}
model1 <- glmer(appropriateness ~ tense + modality + frequency + regularity + modality:regularity + 
                  (1+tense + modality + frequency + regularity + modality:regularity ||Name) + (1|infinitive), csv_cedel2_duplicates_only,
                  family = 'binomial', control = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=50000)))

summary(model1)
```

#in paper currently

## Model 0.7.1 : no 3-way or 2-way interactions

```{r anotheroneabcagain1234567smsm}
model1 <- glmer(appropriateness ~ tense + modality + frequency + regularity + 
                  (1+tense + modality + frequency + regularity ||Name) + (1|infinitive), csv_cedel2_duplicates_only,
                  family = 'binomial', control = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=50000)))

summary(model1)
```

#Cohen's d

```{r emmeans123}
#get cohen's d
#divide into groups by tense
#calculate Cohen's d
cohen.d(csv_cedel2_duplicates_only_pret$appropriateness, csv_cedel2_duplicates_only_imp$appropriateness)
#0.3354277 (small) according to P&O 2014

#effect size by modality?
written <- csv_cedel2_duplicates_only %>%
  filter(Modality == 'Written')

spoken <- csv_cedel2_duplicates_only %>%
  filter(Modality == 'Spoken')
#view(csv_cedel2_duplicates_only)

cohen.d(written$appropriateness, spoken$appropriateness)
#0.6055081 (medium)
```
## Preterit

#in paper currently

## Model 1.3.1 : apr \~ frequency + (1+frequency\|Name) + (1\|inf)

```{r new7again}
model3 <- glmer(appropriateness ~ frequency +
                  (1+frequency||Name) + (1|infinitive), csv_cedel2_duplicates_only_pret,
                  family = 'binomial', control = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=50000)))


summary(model3)
```

No effect

## Model 1.4 : apr \~ modality + (1+modality\|\|Name) + (1\|inf)

```{r new74}
model4 <- glmer(appropriateness ~ modality +
                  (1+modality||Name) + (1|infinitive), csv_cedel2_duplicates_only_pret,
                  family = 'binomial', control = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=50000)))


summary(model4)
```

Significant effect of modality

## Model 1.5 : apr \~ modality \* frequency + (1+modality\*frequency\|\|Name) + (1\|inf)

```{r new745zzz}
model5 <- glmer(appropriateness ~ modality + frequency + modality:frequency +
                  (1+modality*frequency||Name) + (1|infinitive), csv_cedel2_duplicates_only_pret,
                  family = 'binomial', control = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=50000)))


summary(model5)
```

## Model 1.5.1 : apr \~ modality + frequency + (1+modality+frequency\|\|Name) + (1\|inf)

```{r new745}
model5 <- glmer(appropriateness ~ modality + frequency +
                  (1+modality+frequency||Name) + (1|infinitive), csv_cedel2_duplicates_only_pret,
                  family = 'binomial', control = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=50000)))


summary(model5)
```

STill only effect of modality.


## Imperfect

#in paper currently

## Model 1.3 : apr \~ frequency + (1+frequency\|Name) + (1\|inf)

```{r new 111}
model3 <- glmer(appropriateness ~ frequency +
                  (1+frequency||Name) + (1|infinitive), csv_cedel2_duplicates_only_imp,
                  family = 'binomial', control = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=50000)))

summary(model3)
```

## Model 1.4 : apr \~ modality + (1+modality\|\|Name) + (1\|inf)

```{r new74imp}
model4 <- glmer(appropriateness ~ modality +
                  (1+modality||Name) + (1|infinitive), csv_cedel2_duplicates_only_imp,
                  family = 'binomial', control = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=50000)))


summary(model4)
```

Significant effect of modality. Small number of observations.

Just trying out other models now.

#potentially in paper

## Model 1.5 : apr \~ modality \* frequency + (1+modality\*frequency\|\|Name) + (1\|inf)

```{r new745impxxx}
model5 <- glmer(appropriateness ~ modality + frequency + modality:frequency +
                  (1+modality*frequency||Name) + (1|infinitive), csv_cedel2_duplicates_only_imp,
                  family = 'binomial', control = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=50000)))


summary(model5)
```

## Model 1.5.1 : apr \~ modality + frequency + (1+modality+frequency\|\|Name) + (1\|inf)

```{r new745imp}
model5 <- glmer(appropriateness ~ modality + frequency +
                  (1+modality+frequency||Name) + (1|infinitive), csv_cedel2_duplicates_only_imp,
                  family = 'binomial', control = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=50000)))


summary(model5)
```

Thanks for reading! :)
